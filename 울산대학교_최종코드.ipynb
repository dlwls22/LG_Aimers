{"cells":[{"cell_type":"markdown","id":"f7444f30-0883-4a87-8e00-c5e5591a2a26","metadata":{"id":"f7444f30-0883-4a87-8e00-c5e5591a2a26"},"source":["## Import"]},{"cell_type":"code","execution_count":null,"id":"b85832b1-9f31-41e4-b934-cc260e5b3b1d","metadata":{"id":"b85832b1-9f31-41e4-b934-cc260e5b3b1d"},"outputs":[],"source":["import random\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from sklearn.preprocessing import LabelEncoder\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"id":"b0259cfd-b37c-4716-aacf-c91d77e41480","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0259cfd-b37c-4716-aacf-c91d77e41480","outputId":"47c53853-f18a-42fc-d59d-7bf768ecfa90","executionInfo":{"status":"ok","timestamp":1693395670446,"user_tz":-540,"elapsed":5,"user":{"displayName":"이진","userId":"07182137582732274273"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","device"]},{"cell_type":"markdown","id":"07c2d47b-e9da-47e5-9155-cce997e63481","metadata":{"id":"07c2d47b-e9da-47e5-9155-cce997e63481"},"source":["## Hyperparameter Setting"]},{"cell_type":"code","execution_count":null,"id":"c9f50013-6513-44fd-8e48-06dd12ec3f63","metadata":{"id":"c9f50013-6513-44fd-8e48-06dd12ec3f63"},"outputs":[],"source":["CFG = {\n","    'TRAIN_WINDOW_SIZE':60,\n","    'PREDICT_SIZE':21,\n","    'EPOCHS':10,\n","    'LEARNING_RATE':1e-4,\n","    'BATCH_SIZE':4096,\n","    'SEED': 42\n","}"]},{"cell_type":"code","execution_count":null,"id":"44cdbe67-eda2-42ef-bc35-0a2bfd99f211","metadata":{"id":"44cdbe67-eda2-42ef-bc35-0a2bfd99f211"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CFG['SEED'])"]},{"cell_type":"markdown","id":"7d68c38e","metadata":{"id":"7d68c38e"},"source":["### 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"id":"07fd1ad3","metadata":{"id":"07fd1ad3"},"outputs":[],"source":["train_cat = pd.read_csv('/train.csv').drop(columns=['ID', '제품'])\n","train_num = pd.read_csv('/train.csv').drop(columns=['ID', '제품'])\n","\n","train_cat = train_cat.iloc[:,:4]\n","train_num = train_num.iloc[:, 4:-41]\n","\n","train_data = pd.concat([train_cat, train_num], axis=1)\n","\n","out_train = pd.read_csv('train.csv')\n","out_train = out_train.iloc[:, -7:]\n","\n","train_data = pd.concat([train_data, out_train], axis=1)"]},{"cell_type":"code","execution_count":null,"id":"9509bd54-9333-4ec7-b197-b70d3c1408ef","metadata":{"id":"9509bd54-9333-4ec7-b197-b70d3c1408ef"},"outputs":[],"source":["# 숫자형 변수들의 min-max scaling을 수행하는 코드입니다. real_train\n","numeric_cols = train_data.columns[4:]\n","\n","# 각 column의 min 및 max 계산\n","min_values = train_data[numeric_cols].min(axis = 1)\n","max_values = train_data[numeric_cols].max(axis = 1)\n","\n","# 각 행의 범위(max-min)를 계산하고, 범위가 0인 경우 1로 대체\n","ranges = max_values - min_values\n","ranges[ranges == 0] = 1\n","\n","# min-max scaling 수행\n","train_data[numeric_cols] = (train_data[numeric_cols].subtract(min_values, axis = 0)).div(ranges, axis = 0)\n","\n","# max와 min 값을 dictionary 형태로 저장\n","scale_min_dict = min_values.to_dict()\n","scale_max_dict = max_values.to_dict()"]},{"cell_type":"code","execution_count":null,"id":"eO5iMUSxC3zi","metadata":{"id":"eO5iMUSxC3zi"},"outputs":[],"source":["# 1. 범주형 변수 레이블 인코딩\n","label_encoders = {}  # 각 컬럼별로 LabelEncoder를 저장\n","categorical_columns = ['대분류', '중분류', '소분류', '브랜드']\n","\n","for col in categorical_columns:\n","    le = LabelEncoder()\n","    train_data[col] = le.fit_transform(train_data[col]).astype(int)\n","    label_encoders[col] = le\n","\n","# 2. 임베딩 레이어 생성\n","class CategoricalEmbedding(nn.Module):\n","    def __init__(self, input_sizes, embedding_dims):\n","        super(CategoricalEmbedding, self).__init__()\n","\n","        # 각 범주형 변수에 대한 임베딩 레이어를 생성\n","        self.embeddings = nn.ModuleList([\n","            nn.Embedding(input_size, dim) for input_size, dim in zip(input_sizes, embedding_dims)\n","        ])\n","\n","    def forward(self, x):\n","        # x: [batch_size, num_categorical_features]\n","        embedded = [embedding(x[:, i]) for i, embedding in enumerate(self.embeddings)]\n","        return torch.cat(embedded, dim=1)  # 연결된 임베딩 벡터 반환\n","\n","# 각 범주형 변수의 최대값 (레이블 인코딩된 값) + 1을 구함\n","input_sizes = [train_data[col].max() + 1 for col in categorical_columns]\n","\n","# 임베딩 차원 설정\n","embedding_dims = [int(np.sqrt(size) // 2) for size in input_sizes]\n","\n","model = CategoricalEmbedding(input_sizes, embedding_dims)\n","\n","# 모든 행에 대한 범주형 데이터를 PyTorch 텐서로 변환\n","all_data_tensor = torch.tensor(train_data[categorical_columns].values, dtype = torch.long)\n","\n","# 임베딩 모델에 텐서를 입력하여 임베딩된 값을 얻음\n","with torch.no_grad():\n","    all_embedded_values = model(all_data_tensor)\n","\n","# 임베딩된 텐서를 numpy 배열로 변환\n","all_embedded_np = all_embedded_values.numpy()\n","\n","# 임베딩된 값을 저장할 임시 데이터프레임 생성\n","embedded_df = pd.DataFrame()\n","\n","start_idx = 0\n","# 각 범주형 변수에 대한 임베딩된 값을 새로운 컬럼으로 추가\n","for i, col in enumerate(categorical_columns):\n","    col_names = [f\"{col}_{j}\" for j in range(embedding_dims[i])]\n","    for idx, name in enumerate(col_names):\n","        embedded_df[name] = all_embedded_np[:, start_idx + idx]\n","    start_idx += embedding_dims[i]\n","\n","# 레이블 인코딩된 컬럼 제거\n","train_data.drop(columns=categorical_columns, inplace = True)\n","\n","# 임베딩된 데이터를 원본 데이터프레임의 앞 부분에 추가\n","train_data = pd.concat([embedded_df, train_data], axis = 1)\n","\n","# 결과 확인\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"id":"0gLeTuOrgVg-","metadata":{"id":"0gLeTuOrgVg-"},"outputs":[],"source":["train_data.iloc[:, 33]"]},{"cell_type":"code","execution_count":null,"id":"0GGPaMw8GtL3","metadata":{"id":"0GGPaMw8GtL3"},"outputs":[],"source":["def make_train_data(data, train_size = CFG['TRAIN_WINDOW_SIZE'], predict_size = CFG['PREDICT_SIZE']):\n","    STEP_SIZE = 2\n","\n","    num_rows = len(data)\n","    window_size = train_size + predict_size\n","    adjusted_size = (len(data.columns) - window_size + 1) // STEP_SIZE\n","\n","    input_data = np.empty((num_rows * adjusted_size, train_size, len(data.iloc[0, :33]) + 1))\n","    target_data = np.empty((num_rows * adjusted_size, predict_size))\n","\n","    for i in tqdm(range(num_rows)):\n","        encode_info = np.array(data.iloc[i, :33])\n","        sales_data = np.array(data.iloc[i, 33:])\n","\n","        for j in range(0, len(sales_data) - window_size + 1, STEP_SIZE):\n","            window = sales_data[j: j + window_size]\n","            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n","            input_data[i * adjusted_size + j // STEP_SIZE] = temp_data\n","            target_data[i * adjusted_size + j // STEP_SIZE] = window[train_size:]\n","\n","    return input_data, target_data"]},{"cell_type":"code","execution_count":null,"id":"9bf39b0f-64f4-4126-9a3d-da5de9f624d5","metadata":{"id":"9bf39b0f-64f4-4126-9a3d-da5de9f624d5"},"outputs":[],"source":["def make_predict_data(data, train_size = CFG['TRAIN_WINDOW_SIZE']):\n","    num_rows = len(data)\n","\n","    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :33]) + 1))\n","\n","    for i in tqdm(range(num_rows)):\n","        encode_info = np.array(data.iloc[i, :33])\n","        sales_data = np.array(data.iloc[i, -train_size:])\n","\n","        window = sales_data[-train_size : ]\n","        temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n","        input_data[i] = temp_data\n","\n","    return input_data"]},{"cell_type":"code","execution_count":null,"id":"3c203f18-dfe9-430a-8082-f1143267b296","metadata":{"id":"3c203f18-dfe9-430a-8082-f1143267b296"},"outputs":[],"source":["train_input, train_target = make_train_data(train_data)\n","test_input = make_predict_data(train_data)"]},{"cell_type":"code","execution_count":null,"id":"3c710abd-1be0-4926-803f-c732d7bffdb5","metadata":{"id":"3c710abd-1be0-4926-803f-c732d7bffdb5"},"outputs":[],"source":["data_len = len(train_input)\n","val_input = train_input[-int(data_len * 0.2):]\n","val_target = train_target[-int(data_len * 0.2):]\n","train_input = train_input[:-int(data_len * 0.2)]\n","train_target = train_target[:-int(data_len * 0.2)]"]},{"cell_type":"code","execution_count":null,"id":"3be176ad-ccc8-425c-9627-f583c0647489","metadata":{"id":"3be176ad-ccc8-425c-9627-f583c0647489"},"outputs":[],"source":["train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape"]},{"cell_type":"markdown","id":"3b2f3d76-fcf4-4866-a578-6bb76783bbed","metadata":{"id":"3b2f3d76-fcf4-4866-a578-6bb76783bbed"},"source":["### Custom Dataset"]},{"cell_type":"code","execution_count":null,"id":"4ec0a970-4d99-486d-b9b5-210f3cdca353","metadata":{"id":"4ec0a970-4d99-486d-b9b5-210f3cdca353"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.Y = Y\n","\n","    def __getitem__(self, index):\n","        if self.Y is not None:\n","            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n","        return torch.Tensor(self.X[index])\n","\n","    def __len__(self):\n","        return len(self.X)"]},{"cell_type":"code","execution_count":null,"id":"3614347b-da14-466f-9d04-b81e5448a9bd","metadata":{"id":"3614347b-da14-466f-9d04-b81e5448a9bd"},"outputs":[],"source":["train_dataset = CustomDataset(train_input, train_target)\n","train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle = True, num_workers = 0)\n","\n","val_dataset = CustomDataset(val_input, val_target)\n","val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle = False, num_workers = 0)"]},{"cell_type":"markdown","id":"c63f0b66-817d-49ff-9163-a975fb0f239d","metadata":{"id":"c63f0b66-817d-49ff-9163-a975fb0f239d"},"source":["### 모델 선언"]},{"cell_type":"code","execution_count":null,"id":"0f402c3a","metadata":{"id":"0f402c3a"},"outputs":[],"source":["class Mish(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x * torch.tanh(nn.functional.softplus(x))\n","\n","class StackedLSTMModel(nn.Module):\n","    def __init__(self, input_size = 34, hidden_size = 1024, output_size = CFG['PREDICT_SIZE'], num_layers = 3, dropout = 0.5):\n","        super(StackedLSTMModel, self).__init__()\n","\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","\n","        # LSTM 레이어 내부에 dropout 적용\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, dropout = (0 if num_layers == 1 else dropout), batch_first = True)\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size//2),\n","            Mish(),\n","            nn.Linear(hidden_size//2, output_size)\n","        )\n","\n","        self.actv = Mish()\n","\n","    def forward(self, x):\n","        # x shape: (B, TRAIN_WINDOW_SIZE, 5)\n","        batch_size = x.size(0)\n","        hidden = self.init_hidden(batch_size, x.device)\n","\n","        # LSTM layers\n","        x, hidden = self.lstm(x, hidden)\n","\n","        # Only use the last output sequence\n","        last_output = x[:, -1, :]\n","\n","        # Fully connected layer\n","        output = self.actv(self.fc(last_output))\n","\n","        return output.squeeze(1)\n","\n","    def init_hidden(self, batch_size, device):\n","        # Initialize hidden state and cell state\n","        return (torch.zeros(self.num_layers, batch_size, self.hidden_size, device = device),\n","                torch.zeros(self.num_layers, batch_size, self.hidden_size, device = device))\n"]},{"cell_type":"markdown","id":"b4f79f7d","metadata":{"id":"b4f79f7d"},"source":["### 모델 학습"]},{"cell_type":"code","execution_count":null,"id":"ff73d757-32d5-4868-afbb-1b9f2ea13826","metadata":{"id":"ff73d757-32d5-4868-afbb-1b9f2ea13826"},"outputs":[],"source":["model = StackedLSTMModel()\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n","# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n","\n","class EarlyStopping:\n","    def __init__(self, patience = 2, verbose=False, delta = 0):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.counter = 0\n","\n","def train(model, optimizer, train_loader, val_loader, device):\n","    model.to(device)\n","    criterion = nn.MSELoss().to(device)\n","    best_loss = 9999999\n","    best_model = None\n","\n","    early_stopping = EarlyStopping(patience = 2, verbose = True)\n","\n","    for epoch in range(1, CFG['EPOCHS']+1):\n","        model.train()\n","        train_loss = []\n","        train_mae = []\n","        for X, Y in tqdm(iter(train_loader)):\n","            X = X.to(device)\n","            Y = Y.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            output = model(X)\n","            loss = criterion(output, Y)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss.append(loss.item())\n","\n","        val_loss = validation(model, val_loader, criterion, device)\n","        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n","\n","        if best_loss > val_loss:\n","            best_loss = val_loss\n","            best_model = model\n","            print('Model Saved')\n","\n","        early_stopping(val_loss, model)\n","        if early_stopping.early_stop:\n","            print(\"Early stopping\")\n","            break\n","\n","    return best_model"]},{"cell_type":"code","execution_count":null,"id":"bbe1802a-35ff-4b43-a1a8-16c8079baf68","metadata":{"id":"bbe1802a-35ff-4b43-a1a8-16c8079baf68"},"outputs":[],"source":["def validation(model, val_loader, criterion, device):\n","    model.eval()\n","    val_loss = []\n","\n","    with torch.no_grad():\n","        for X, Y in tqdm(iter(val_loader)):\n","            X = X.to(device)\n","            Y = Y.to(device)\n","\n","            output = model(X)\n","            loss = criterion(output, Y)\n","\n","            val_loss.append(loss.item())\n","    return np.mean(val_loss)"]},{"cell_type":"markdown","id":"1c83fa73-30d5-489c-852b-d655f76a200c","metadata":{"id":"1c83fa73-30d5-489c-852b-d655f76a200c"},"source":["## Run !!"]},{"cell_type":"code","execution_count":null,"id":"a1570b00-a309-4e5e-b53d-5848ba53eb19","metadata":{"id":"a1570b00-a309-4e5e-b53d-5848ba53eb19"},"outputs":[],"source":["infer_model = train(model, optimizer, train_loader, val_loader, device)"]},{"cell_type":"markdown","id":"36b20af7-f5b1-4a7a-8eb9-7dde5bbf3d04","metadata":{"id":"36b20af7-f5b1-4a7a-8eb9-7dde5bbf3d04"},"source":["## 모델 추론"]},{"cell_type":"code","execution_count":null,"id":"b01d7ca0-899e-4515-a43e-890549f8f3c7","metadata":{"id":"b01d7ca0-899e-4515-a43e-890549f8f3c7"},"outputs":[],"source":["test_dataset = CustomDataset(test_input, None)\n","test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle = False, num_workers = 0)"]},{"cell_type":"code","execution_count":null,"id":"214f30d4-2b19-479f-89b7-bf5bb2adc111","metadata":{"id":"214f30d4-2b19-479f-89b7-bf5bb2adc111"},"outputs":[],"source":["def inference(model, test_loader, device):\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for X in tqdm(iter(test_loader)):\n","            X = X.to(device)\n","\n","            output = model(X)\n","\n","            # 모델 출력인 output을 CPU로 이동하고 numpy 배열로 변환\n","            output = output.cpu().numpy()\n","\n","            predictions.extend(output)\n","\n","    return np.array(predictions)"]},{"cell_type":"code","execution_count":null,"id":"6b76e053-6fd2-44a7-8631-d903e7ffa292","metadata":{"id":"6b76e053-6fd2-44a7-8631-d903e7ffa292"},"outputs":[],"source":["pred = inference(infer_model, test_loader, device)"]},{"cell_type":"code","execution_count":null,"id":"517978aa-445a-4ece-9217-432682f71230","metadata":{"id":"517978aa-445a-4ece-9217-432682f71230"},"outputs":[],"source":["# 추론 결과를 inverse scaling\n","for idx in range(len(pred)):\n","    pred[idx, :] = pred[idx, :] * (scale_max_dict[idx] - scale_min_dict[idx]) + scale_min_dict[idx]\n","\n","# 결과 후처리\n","pred = np.round(pred, 0).astype(int)"]},{"cell_type":"code","execution_count":null,"id":"c90fa77e-fd03-4539-98fe-563fe2a25121","metadata":{"id":"c90fa77e-fd03-4539-98fe-563fe2a25121"},"outputs":[],"source":["pred.shape"]},{"cell_type":"markdown","id":"a48b50eb-d2d8-4c2d-a5e7-9607220fd794","metadata":{"id":"a48b50eb-d2d8-4c2d-a5e7-9607220fd794"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"id":"b78c84bb-5dbe-4fb3-aff0-7e229ae29a8d","metadata":{"id":"b78c84bb-5dbe-4fb3-aff0-7e229ae29a8d"},"outputs":[],"source":["submit = pd.read_csv('/sample_submission.csv')\n","submit.head()"]},{"cell_type":"code","execution_count":null,"id":"2db62d9c-b3ad-440a-8cc7-4897b2e4860f","metadata":{"id":"2db62d9c-b3ad-440a-8cc7-4897b2e4860f"},"outputs":[],"source":["submit.iloc[:,1:] = pred\n","submit.head()"]},{"cell_type":"code","execution_count":null,"id":"4142f749-f20f-4797-b586-581e5c778297","metadata":{"id":"4142f749-f20f-4797-b586-581e5c778297"},"outputs":[],"source":["submit.to_csv('/University_of_Ulsan.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}